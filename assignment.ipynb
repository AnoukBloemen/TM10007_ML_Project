{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "outputs": [],
      "source": [
        "# Run this to use from colab environment\n",
        "# !pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing packages"
      ],
      "metadata": {
        "id": "g1cum_GWnJzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# General packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "import seaborn\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "\n",
        "# Scoring methods\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
        "\n",
        "# Preprocessing steps\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.stats import shapiro\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Feature selection\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import decomposition"
      ],
      "metadata": {
        "id": "RPltM9lAmbIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXiW521Kl09k"
      },
      "source": [
        "# Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "20bc3855-8c15-40d6-c78e-55307a363055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of samples: 115\n",
            "The number of columns: 494\n"
          ]
        }
      ],
      "source": [
        "## Data loading functions. Uncomment the one you want to use\n",
        "from worclipo.load_data import load_data\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a split in the data\n",
        "\n",
        "A training and test set are created. The training set will be used to fit the classifier, while the test set is remained untouched until it is used for testing the trained classifier.\n",
        "\n",
        "Split is stratified so labels are present in both sets in same proportions."
      ],
      "metadata": {
        "id": "EnN20JHuvvaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract columns with labels\n",
        "Y = data.pop('label').replace({'lipoma':0, 'liposarcoma':1}) #moeten we misschien nog ook de ID poppen?\n",
        "print(f'The proportion of the labels is: {sum(Y)/len(Y)}')\n",
        "\n",
        "# Extract the rest of the data (without the labels)\n",
        "X = data\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.2, stratify=Y)\n",
        "\n",
        "print(f'Size of training set: {X_train.shape}')\n",
        "print(f'Size of test set: {X_test.shape}')"
      ],
      "metadata": {
        "id": "qTjJAJ-7vtzg",
        "outputId": "87616730-f0ad-459a-f55f-7cf8422110d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The proportion of the labels is: 0.5043478260869565\n",
            "Size of training set: (92, 493)\n",
            "Size of test set: (23, 493)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspecting distribution of features\n",
        "To determine data distribution of train set"
      ],
      "metadata": {
        "id": "pJBR7ywnn50T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visually inspect distribution of features"
      ],
      "metadata": {
        "id": "q7JVrtMS2mih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## UITEINDELIJK WEGHALEN DIT!!\n",
        "\n",
        "#Check if Gaussian distribution per column\n",
        "# if Gaussian distribution, take mean for filling empty cells (later in script)\n",
        "# if not Gaussion distribution (and outliers or skewed), take median for filling empty cells (later in script)\n",
        "\n",
        "# plt.hist(X_train.iloc[:, 15], bins=30, edgecolor='k') # Change number of colum to see distribution (between width dataframe)\n",
        "plt.hist(X_train['PREDICT_original_tf_Gabor_entropy_F0.2_A1.57'], bins=30, edgecolor='k') # Change number of colum to see distribution (between width dataframe)\n",
        "\n",
        "\n",
        "plt.title('Distribution of Feature')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# print(X_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Llz2aPWlneOo",
        "outputId": "e933db71-a153-46a5-fd86-af4c6d5471eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Data"
      ],
      "metadata": {
        "id": "cL18MbR93P-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Values\n",
        "Determining cells with missing values and filling these"
      ],
      "metadata": {
        "id": "U8-WunWt4Q6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling missing values with correct value based on type of distribution per column\n",
        "\n",
        "# Definieer alpha voor de significantietest BEARGUMENTEREN WAAROM DEZE TEST IN REPORT + WAARDE\n",
        "alpha = 0.05\n",
        "\n",
        "# Initialiseer een teller voor normaal verdeelde kolommen\n",
        "normal_distributed_columns_count = 0\n",
        "not_normal_distributed_columns_count = 0\n",
        "nans_found_in_column_count = 0\n",
        "\n",
        "# Loop door elke kolom in de DataFrame en voer Shapiro-Wilk test uit\n",
        "for column in X_train:\n",
        "    stat, p = shapiro(X_train[column])\n",
        "    if p > alpha:\n",
        "        # print(column)\n",
        "        normal_distributed_columns_count += 1  # Tel kolom als normaal verdeeld\n",
        "        if X_train[column].isna().sum() > 0:\n",
        "            X_train[column].fillna(X_train[column].mean)\n",
        "            nans_found_in_column_count += 1\n",
        "    else:\n",
        "        not_normal_distributed_columns_count += 1  # Tel kolom als normaal verdeeld\n",
        "        if X_train[column].isna().sum() > 0:\n",
        "            X_train[column].fillna(X_train[column].median)\n",
        "            nans_found_in_column_count += 1\n",
        "\n",
        "print(f'The number of normal distributed columns is: {normal_distributed_columns_count}')\n",
        "print(f'The number of not normal distributed columns is: {not_normal_distributed_columns_count}')\n",
        "print(f'The number of columns where nans were filled: {nans_found_in_column_count}')"
      ],
      "metadata": {
        "id": "CpaHZZda6SE1",
        "outputId": "6a87621b-7813-4b38-80ee-861beaa4c482",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of normal distributed columns is: 89\n",
            "The number of not normal distributed columns is: 404\n",
            "The number of columns where nans were filled: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/stats/_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
            "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Scaling\n",
        "Scale features in Train set"
      ],
      "metadata": {
        "id": "ZB1ABL14902-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Motivation of chosen scaler"
      ],
      "metadata": {
        "id": "fAtSOQHKkYAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define counter for columns with many outliers\n",
        "columns_with_many_outliers_count = 0\n",
        "\n",
        "for column in X_train:\n",
        "    Q1 = X_train[column].quantile(0.25)\n",
        "    Q3 = X_train[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Calculate number of outliers\n",
        "    outliers = X_train[(X_train[column] < (Q1 - 1.5 * IQR)) | (X_train[column] > (Q3 + 1.5 * IQR))]\n",
        "    outliers_count = outliers.shape[0]\n",
        "\n",
        "    # Define what 'many' outliers mean\n",
        "    if outliers_count > 0.05 * X_train.shape[0]:\n",
        "        columns_with_many_outliers_count += 1\n",
        "        # print(f\"{column} has many outliers: {outliers_count} outliers\")\n",
        "\n",
        "print(f\"Number of columns with many outliers: {columns_with_many_outliers_count}/{len(X_train.columns)}\")\n"
      ],
      "metadata": {
        "id": "L5ePShRwmJrY",
        "outputId": "6a2808f7-87c8-401f-c8ac-c1744d962b1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of columns with many outliers: 201/493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scaling the data"
      ],
      "metadata": {
        "id": "oS7Re7CSkiMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a RobustScaler object\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Fit the scaler on the training data\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Transform both training and testing data using the scaler\n",
        "X_train_sc = (scaler.transform(X_train))\n",
        "X_test_sc = scaler.transform(X_test)\n",
        "\n",
        "X_train_sc = pd.DataFrame(X_train_sc)\n",
        "X_test_sc = pd.DataFrame(X_test_sc)"
      ],
      "metadata": {
        "id": "vR4vx1oJoZBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspecting data"
      ],
      "metadata": {
        "id": "7afe2lGEowDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection and extraction"
      ],
      "metadata": {
        "id": "bTxLT12kH1u5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero variance\n",
        "selector = VarianceThreshold(threshold=0)\n",
        "vs_fit = selector.fit(X_train_sc)\n",
        "\n",
        "X_train_zv = vs_fit.transform(X_train_sc)\n",
        "X_test_zv = vs_fit.transform(X_test_sc)\n",
        "\n",
        "# Willen we dit nou van train of test set weten?\n",
        "print(f'Amount of features with zero variance: {X_train_sc.shape[1]-X_train_zv.shape[1]}')\n",
        "print(f'Amount of features after removing features with zero variance: {X_train_zv.shape[1]}')"
      ],
      "metadata": {
        "id": "isFVugQAoGXH",
        "outputId": "6b7507fc-f689-46d8-9019-b672cdd3770b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of features with zero variance: 19\n",
            "Amount of features after removing features with zero variance: 474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection using K best - chi squared test\n",
        "fs_chi = SelectKBest(f_classif, k=5).fit(X_train_zv, Y_train)\n",
        "\n",
        "X_train_fs = fs_chi.transform(X_train_zv)\n",
        "X_test_fs = fs_chi.transform(X_test_zv)\n",
        "\n",
        "print(X_train_fs.shape)\n",
        "print(X_test_fs.shape)\n"
      ],
      "metadata": {
        "id": "pY2smu5SH9NH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cfda03c-0c1d-4e53-c6a1-9b9094bb570e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(92, 5)\n",
            "(23, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # PCA\n",
        "# # If there are more samples than features left after RFECV then perform PCA\n",
        "# pca = decomposition.PCA(n_components=0.95)\n",
        "# pca.fit(X_train_zv)\n",
        "# X_train_fs = pca.transform(X_train_zv)\n",
        "# X_test_fs = pca.transform(X_test_zv)"
      ],
      "metadata": {
        "id": "1HlXchplsHTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifiers"
      ],
      "metadata": {
        "id": "NqoGUPrpTjMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "9pY9Z5AwTk4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define cv and knn classifier\n",
        "cv_knn = 6\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Define range for n neighbours to be max the size of one split\n",
        "max_n_neighbors = len(X_train_fs) // cv_knn - 1\n",
        "print(\"Max number of neighbors:\", max_n_neighbors)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': list(range(1, max_n_neighbors, 2)),\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]  # p=1 for Manhattan distance, p=2 for Euclidean distance\n",
        "}\n",
        "\n",
        "# Create the grid search object with ROC AUC scoring\n",
        "grid_search_knn = GridSearchCV(knn_model, param_grid_knn, cv=cv_knn, scoring='roc_auc')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search_knn.fit(X_train_fs, Y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", grid_search_knn.best_params_)\n",
        "\n",
        "# Get the best estimator\n",
        "best_knn_model = grid_search_knn.best_estimator_\n",
        "print(f'Best estimator: {best_knn_model}')\n",
        "\n",
        "# See how well model works on train data:\n",
        "pred_knn_train = best_knn_model.predict(X_train_fs)\n",
        "pred_proba_knn_train = best_knn_model.predict_proba(X_train_fs)[:,1]\n",
        "\n",
        "roc_auc_knn_train = roc_auc_score(Y_train, pred_proba_knn_train)\n",
        "print('ROC AUC train =', roc_auc_knn_train)\n",
        "accuracy_knn_train = accuracy_score(Y_train, pred_knn_train)\n",
        "print('Accuracy train =', accuracy_knn_train)\n",
        "\n",
        "# See how well model works on test data:\n",
        "pred_knn_test = best_knn_model.predict(X_test_fs)\n",
        "pred_proba_knn_test = best_knn_model.predict_proba(X_test_fs)[:,1]\n",
        "\n",
        "roc_auc_knn_test = roc_auc_score(Y_test, pred_proba_knn_test)\n",
        "print('ROC AUC test =', roc_auc_knn_test)\n",
        "accuracy_knn_test = accuracy_score(Y_test, pred_knn_test)\n",
        "print('Accuracy test =', accuracy_knn_test)"
      ],
      "metadata": {
        "id": "KSjGJIfWTmUX",
        "outputId": "d902697e-1dc5-44b3-b096-91e3e5ab6d59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n",
            "Best estimator: KNeighborsClassifier(weights='distance')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        46\n",
            "           1       1.00      1.00      1.00        46\n",
            "\n",
            "    accuracy                           1.00        92\n",
            "   macro avg       1.00      1.00      1.00        92\n",
            "weighted avg       1.00      1.00      1.00        92\n",
            "\n",
            "ROC AUC = 1.0\n",
            "Accuracy = 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.64      0.64        11\n",
            "           1       0.67      0.67      0.67        12\n",
            "\n",
            "    accuracy                           0.65        23\n",
            "   macro avg       0.65      0.65      0.65        23\n",
            "weighted avg       0.65      0.65      0.65        23\n",
            "\n",
            "ROC AUC = 0.6515151515151515\n",
            "Accuracy = 0.6521739130434783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest"
      ],
      "metadata": {
        "id": "Czr39UJNT1l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise the effect of n_estimators\n",
        "roc_auc_scores = []\n",
        "\n",
        "for k in range(1, 100):\n",
        "    rf_model = RandomForestClassifier(n_estimators=k)\n",
        "    rf_model.fit(X_train_fs, Y_train)\n",
        "\n",
        "    pred_proba_RF_test =rf_model.predict_proba(X_test_fs)[:,1]\n",
        "    roc_auc_RF_test = roc_auc_score(Y_test, pred_proba_RF_test)\n",
        "    roc_auc_scores.append(roc_auc_RF_test)\n",
        "\n",
        "# Plot the relationship between K and testing roc auc\n",
        "fig = plt.figure(figsize=(15,4))\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "plt.plot(range(1, 100), roc_auc_scores)\n",
        "plt.xlabel('Value of n_estimators for Random Forest Classifier')\n",
        "plt.ylabel('ROC AUC')\n",
        "\n",
        "# Find the index of the (first) maximum ROC AUC score\n",
        "max_roc_auc_index = np.argmax(roc_auc_scores)\n",
        "\n",
        "# Find the maximum ROC AUC score and its corresponding n_estimators\n",
        "max_roc_auc = roc_auc_scores[max_roc_auc_index]\n",
        "best_n_estimators_roc_auc = max_roc_auc_index + 1  # Adding 1 to convert index to n_estimators value\n",
        "\n",
        "# Print the results\n",
        "print(\"Maximum ROC AUC:\", max_roc_auc, \"at n_estimators =\", best_n_estimators_roc_auc)\n",
        "\n",
        "# The model shows there is a lot of variety in which estimator is best\n",
        "# But since it is best to use a more simple model (with the same results)\n",
        "# We choose n_estimators = 15\n",
        "\n",
        "# Define cv and RF classifier\n",
        "cv_RF = 7\n",
        "RF_model = RandomForestClassifier(n_estimators=15)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid_RF = {\n",
        "    'bootstrap': [True, False],\n",
        "    'min_samples_leaf': list(range(1, 7, 2))\n",
        "}\n",
        "\n",
        "# Create the grid search object with ROC AUC scoring\n",
        "grid_search_RF = GridSearchCV(RF_model, param_grid_RF, cv=cv_RF, scoring='roc_auc', error_score='raise')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search_RF.fit(X_train_fs, Y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", grid_search_RF.best_params_)\n",
        "\n",
        "# Get the best estimator\n",
        "best_RF_model = grid_search_RF.best_estimator_\n",
        "print(best_RF_model)\n",
        "\n",
        "# See how well model works on train data:\n",
        "pred_RF_train = best_RF_model.predict(X_train_fs)\n",
        "pred_proba_RF_train = best_RF_model.predict_proba(X_train_fs)[:,1]\n",
        "\n",
        "roc_auc_RF_train = roc_auc_score(Y_train, pred_proba_RF_train)\n",
        "print('ROC AUC train=', roc_auc_RF_train)\n",
        "accuracy_RF_train = accuracy_score(Y_train, pred_RF_train)\n",
        "print('Accuracy train=', accuracy_RF_train)\n",
        "\n",
        "# See how well model works on test data:\n",
        "pred_RF_test = best_RF_model.predict(X_test_fs)\n",
        "pred_proba_RF_test = best_RF_model.predict_proba(X_test_fs)[:,1]\n",
        "\n",
        "roc_auc_RF_test = roc_auc_score(Y_test, pred_proba_RF_test)\n",
        "print('ROC AUC test=', roc_auc_RF_test)\n",
        "accuracy_RF_test = accuracy_score(Y_test, pred_RF_test)\n",
        "print('Accuracy test=', accuracy_RF_test)"
      ],
      "metadata": {
        "id": "KJxj9a1sT3In",
        "outputId": "cdd12154-20e3-443d-fac1-7f8e140a9d72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'bootstrap': True, 'min_samples_leaf': 3}\n",
            "RandomForestClassifier(min_samples_leaf=3)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.91      0.91        46\n",
            "           1       0.91      0.91      0.91        46\n",
            "\n",
            "    accuracy                           0.91        92\n",
            "   macro avg       0.91      0.91      0.91        92\n",
            "weighted avg       0.91      0.91      0.91        92\n",
            "\n",
            "ROC AUC = 0.9130434782608697\n",
            "Accuracy = 0.9130434782608695\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.73      0.73        11\n",
            "           1       0.75      0.75      0.75        12\n",
            "\n",
            "    accuracy                           0.74        23\n",
            "   macro avg       0.74      0.74      0.74        23\n",
            "weighted avg       0.74      0.74      0.74        23\n",
            "\n",
            "ROC AUC = 0.7386363636363636\n",
            "Accuracy = 0.7391304347826086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine"
      ],
      "metadata": {
        "id": "k0LOVQXyUA-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define cv and SVM classifier\n",
        "cv_svm = 5\n",
        "svm_model = svm.SVC(probability=True)\n",
        "\n",
        "# Define the parameter grid for SVM\n",
        "param_grid_svm = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10],  # Regularization parameter\n",
        "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],  # Kernel coefficient\n",
        "    'kernel': ['rbf', 'linear', 'poly'] # Kernel type\n",
        "}\n",
        "\n",
        "# Create the grid search object with ROC AUC scoring\n",
        "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=cv_svm, scoring='roc_auc', error_score='raise')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search_svm.fit(X_train_fs, Y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", grid_search_svm.best_params_)\n",
        "\n",
        "# Get the best estimator\n",
        "best_svm_model = grid_search_svm.best_estimator_\n",
        "print(best_svm_model)\n",
        "\n",
        "# See how well model works on train data\n",
        "pred_svm_train = best_svm_model.predict(X_train_fs)\n",
        "pred_proba_svm_train = best_svm_model.decision_function(X_train_fs)\n",
        "\n",
        "roc_auc_svm_train = roc_auc_score(Y_train, pred_proba_svm_train)\n",
        "print('ROC AUC train=', roc_auc_svm_train)\n",
        "accuracy_svm_train = accuracy_score(Y_train, pred_svm_train)\n",
        "print('Accuracy train=', accuracy_svm_train)\n",
        "\n",
        "# See how well model works on test data\n",
        "pred_svm_test = best_svm_model.predict(X_test_fs)\n",
        "pred_proba_svm_test = best_svm_model.decision_function(X_test_fs)\n",
        "\n",
        "roc_auc_svm_test = roc_auc_score(Y_test, pred_proba_svm_test)\n",
        "print('ROC AUC test=', roc_auc_svm_test)\n",
        "accuracy_svm_test = accuracy_score(Y_test, pred_svm_test)\n",
        "print('Accuracy test=', accuracy_svm_test)"
      ],
      "metadata": {
        "id": "2AzjJ9b-UDhW",
        "outputId": "4c3121b2-3727-45ac-ede7-4bf5cc30b57b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'C': 1, 'gamma': 'scale'}\n",
            "SVC(C=1, probability=True)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.85      0.80        46\n",
            "           1       0.83      0.74      0.78        46\n",
            "\n",
            "    accuracy                           0.79        92\n",
            "   macro avg       0.80      0.79      0.79        92\n",
            "weighted avg       0.80      0.79      0.79        92\n",
            "\n",
            "ROC AUC = 0.7934782608695652\n",
            "Accuracy = 0.7934782608695652\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.73      0.70        11\n",
            "           1       0.73      0.67      0.70        12\n",
            "\n",
            "    accuracy                           0.70        23\n",
            "   macro avg       0.70      0.70      0.70        23\n",
            "weighted avg       0.70      0.70      0.70        23\n",
            "\n",
            "ROC AUC = 0.696969696969697\n",
            "Accuracy = 0.6956521739130435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualisatie"
      ],
      "metadata": {
        "id": "VL4gP1HNg5Tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Receiver Operating Curve"
      ],
      "metadata": {
        "id": "ZHkb7w9rhCCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the ROC curve of the different classifiers\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Curve')\n",
        "\n",
        "# knn\n",
        "fpr_knn, tpr_knn, _ = roc_curve(Y_test, pred_proba_knn_test)\n",
        "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
        "plt.plot(fpr_knn, tpr_knn, lw=lw, label='knn (AUC = %0.2f)' % roc_auc_knn)\n",
        "\n",
        "# RF\n",
        "fpr_RF, tpr_RF, _ = roc_curve(Y_test, pred_proba_RF_test)\n",
        "roc_auc_RF = auc(fpr_RF, tpr_RF)\n",
        "plt.plot(fpr_RF, tpr_RF, lw=lw, label='RF (AUC = %0.2f)' % roc_auc_RF)\n",
        "\n",
        "# svm\n",
        "fpr_svm, tpr_svm, _ = roc_curve(Y_test, pred_proba_svm_test)\n",
        "roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
        "plt.plot(fpr_svm, tpr_svm, lw=lw, label='svm (AUC = %0.2f)' % roc_auc_svm)\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h5u6TbRYg7qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning curves"
      ],
      "metadata": {
        "id": "8667zPI_hJeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(15,4))\n",
        "\n",
        "# knn\n",
        "ax = fig.add_subplot(1, 3, 1)\n",
        "plot_learning_curve(best_knn_model, 'KNN classifier', X_train_fs, Y_train, ax, ylim=(0.3, 1.03), cv=cv_knn)\n",
        "\n",
        "# RF\n",
        "ax = fig.add_subplot(1, 3, 2)\n",
        "plot_learning_curve(best_RF_model, 'RF classifier', X_train_fs, Y_train, ax, ylim=(0.3, 1.03), cv=cv_RF)\n",
        "\n",
        "# CVM\n",
        "ax = fig.add_subplot(1, 3, 3)\n",
        "plot_learning_curve(best_svm_model, 'SVM classifier', X_train_fs, Y_train, ax, ylim=(0.3, 1.03), cv=cv_svm)"
      ],
      "metadata": {
        "id": "C1EjhRQOhLrp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}